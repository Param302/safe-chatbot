models:
  - type: main
    engine: chatgroq
    model: llama-3.3-70b-versatile
    parameters:
      # temperature: 0.7
      max_tokens: 100

rails:
  input:
    flows:
      - self check input